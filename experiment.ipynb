{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a142c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'BiLoRA'...\n",
      "remote: Enumerating objects: 107, done.\u001b[K\n",
      "remote: Counting objects: 100% (107/107), done.\u001b[K  94% (101/107)\u001b[K\n",
      "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
      "remote: Total 107 (delta 47), reused 85 (delta 25), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (107/107), 4.61 MiB | 10.85 MiB/s, done.\n",
      "Resolving deltas: 100% (47/47), done.\n",
      "/content/BiLoRA\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "!git clone https://github.com/nqh-tq-32052503/BiLoRA.git\n",
    "%cd /content/BiLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a18768ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ..\n",
    "!rm -rf /content/BiLoRA/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31d362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./configs/cifar100_bilora.json\", \"r\") as f:\n",
    "    args = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3faec4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/usr/local/lib/python3.12/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from utils import factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2ae9d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys when loading pretrained weights: set()\n",
      "Unexpected keys when loading pretrained weights: set()\n"
     ]
    }
   ],
   "source": [
    "model = factory.get_model(args['model_name'], args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "483cf7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26849737",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.nn.ModuleList([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a41fead5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(12, 768)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.nn.Embedding(12, 768)\n",
    "a.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "578c2517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(12, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3861f702",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.randint(0, 10, (7, ))\n",
    "cpe = torch.nn.Embedding(10, 768)\n",
    "x = torch.rand(7, 196, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49944f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.rand(7, 196, 768)\n",
    "B = torch.rand(256, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba28255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.5400])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([4.54])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb19af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.5400)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.unsqueeze(0).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78f0003f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 196, 768])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ce563b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(unquantized_tensor: torch.Tensor, embedding_space: torch.Tensor):\n",
    "    batch_size, num_patches, embed_dim = unquantized_tensor.shape\n",
    "    A = unquantized_tensor.reshape(batch_size * num_patches, embed_dim)\n",
    "    dist_matrix = torch.cdist(A, embedding_space, p=2)\n",
    "    selected_indices = torch.argmin(dist_matrix, dim=1).to(torch.long)\n",
    "    R = torch.index_select(embedding_space, 0, selected_indices)\n",
    "    quantized_tensor = R.reshape(batch_size, num_patches, embed_dim)\n",
    "    return quantized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bed0d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(unquantized_tensor: torch.Tensor, embedding_space: torch.Tensor):\n",
    "    batch_size = unquantized_tensor.size(0)\n",
    "    dist_matrix = torch.cdist(unquantized_tensor, embedding_space.unsqueeze(0), p=2) # Shape: (7, 12, 197, 50)\n",
    "    selected_indices = torch.argmin(dist_matrix, dim=-1)\n",
    "    B_expanded = embedding_space.unsqueeze(0).expand(batch_size, -1, -1, -1)\n",
    "    indices_expanded = selected_indices.unsqueeze(-1).expand(-1, -1, -1, 768)\n",
    "    quantized_tensor = torch.gather(B_expanded, 2, indices_expanded)\n",
    "    return quantized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d050a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (-1) isn't allowed in a leading, non-existing dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2974922511.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquantize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipython-input-2053690423.py\u001b[0m in \u001b[0;36mquantize\u001b[0;34m(unquantized_tensor, embedding_space)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mselected_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mB_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mindices_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselected_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mquantized_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB_expanded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_expanded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mquantized_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (-1) isn't allowed in a leading, non-existing dimension 0"
     ]
    }
   ],
   "source": [
    "quantize(A.unsqueeze(0), B.un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d6fcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cpe = torch.index_select(cpe.weight, 0, labels)\n",
    "x = x + selected_cpe.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02990e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_cpe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60f3a124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7313, 0.7603, 0.6274],\n",
       "        [0.7329, 0.2975, 0.5860]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6aaeaf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7171, 0.2873, 0.8857],\n",
       "         [0.6250, 0.8840, 0.2708]],\n",
       "\n",
       "        [[0.7093, 0.3437, 0.5123],\n",
       "         [0.4140, 0.3219, 0.5887]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c835bb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.4483, 1.0476, 1.5131],\n",
       "         [1.3562, 1.6444, 0.8981]],\n",
       "\n",
       "        [[1.4422, 0.6413, 1.0984],\n",
       "         [1.1469, 0.6194, 1.1747]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(2, 3)\n",
    "b = torch.rand(2, 2, 3)\n",
    "c = b + a.unsqueeze(1)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f15d2549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa1f1eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num=10\n",
    "\n",
    "outputs_with_task = torch.zeros_like(outputs)[:,: class_num]\n",
    "for idx, i in enumerate(targets//class_num):\n",
    "    en, be =  class_num*i,  class_num*(i+1)\n",
    "    outputs_with_task[idx] = outputs[idx, en:be]\n",
    "predicts_with_task = outputs_with_task.argmax(dim=1)\n",
    "predicts_with_task = predicts_with_task + (targets// class_num)* class_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7045a154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0407, 0.0391, 0.0711, 0.0452, 0.0365, 0.0647, 0.0323, 0.0374, 0.0548,\n",
       "        0.0645, 0.0359, 0.0667, 0.0547, 0.0469, 0.0372, 0.0323, 0.0844, 0.0340,\n",
       "        0.0857, 0.0358])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e29fb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 11, 11,  8, 11, 12,  4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts_with_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23379c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 12\n",
    "batch_size = 7\n",
    "A = torch.randn(batch_size, num_heads, 197, 64)\n",
    "B = torch.randn(num_heads, 50, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "210e11e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(7, 12, 197, 64)\n",
    "Y = X[:, :, 0, :]\n",
    "Z = X[:, :, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "478e2df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 12, 197, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = torch.cat((Y.unsqueeze(2), Z), dim=2)\n",
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "437a1471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 12, 196, 64])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29daa7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 12, 197, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = quantize(A, B)\n",
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c506a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "num_heads = 12\n",
    "batch_size = 7\n",
    "A = torch.randn(batch_size, num_heads, 197, 64)\n",
    "B = torch.randn(num_heads, 50, 64)\n",
    "\n",
    "dist_matrix = torch.cdist(A, B.unsqueeze(0), p=2) # Shape: (7, 12, 197, 50)\n",
    "selected_indices = torch.argmin(dist_matrix, dim=-1)\n",
    "B_expanded = B.unsqueeze(0).expand(batch_size, -1, -1, -1)\n",
    "indices_expanded = selected_indices.unsqueeze(-1).expand(-1, -1, -1, 64)\n",
    "R = torch.gather(B_expanded, 2, indices_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ffc3b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a679406",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.rand(2, 12, 197, 197)\n",
    "B = torch.rand(2, 12, 197, 197)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f2ee95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:3355: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.4999)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.kl_div(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0da3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 197, 64])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dist_matrix = torch.cdist(A, B, p=2) # Shape: (12, 197, 50)\n",
    "selected_indices = torch.argmin(dist_matrix, dim=2)\n",
    "indices_expanded = selected_indices.unsqueeze(-1).expand(-1, -1, 64)\n",
    "R = torch.gather(B, 1, indices_expanded)\n",
    "\n",
    "print(R.shape) # torch.Size([12, 197, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03029016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([197, 64])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(B, 0, selected_indices).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
