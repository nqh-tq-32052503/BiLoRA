{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a142c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'BiLoRA'...\n",
      "remote: Enumerating objects: 107, done.\u001b[K\n",
      "remote: Counting objects: 100% (107/107), done.\u001b[K  94% (101/107)\u001b[K\n",
      "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
      "remote: Total 107 (delta 47), reused 85 (delta 25), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (107/107), 4.61 MiB | 10.85 MiB/s, done.\n",
      "Resolving deltas: 100% (47/47), done.\n",
      "/content/BiLoRA\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "!git clone https://github.com/nqh-tq-32052503/BiLoRA.git\n",
    "%cd /content/BiLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a18768ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ..\n",
    "!rm -rf /content/BiLoRA/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31d362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./configs/cifar100_bilora.json\", \"r\") as f:\n",
    "    args = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3faec4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/timm/models/helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/usr/local/lib/python3.12/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from utils import factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2ae9d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys when loading pretrained weights: set()\n",
      "Unexpected keys when loading pretrained weights: set()\n"
     ]
    }
   ],
   "source": [
    "model = factory.get_model(args['model_name'], args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "483cf7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def quantize(unquantized_tensor: torch.Tensor, embedding_space: torch.Tensor):\n",
    "    batch_size = unquantized_tensor.size(0)\n",
    "    dist_matrix = torch.cdist(unquantized_tensor, embedding_space.unsqueeze(0), p=2) # Shape: (7, 12, 197, 50)\n",
    "    selected_indices = torch.argmin(dist_matrix, dim=-1)\n",
    "    B_expanded = embedding_space.unsqueeze(0).expand(batch_size, -1, -1, -1)\n",
    "    indices_expanded = selected_indices.unsqueeze(-1).expand(-1, -1, -1, 64)\n",
    "    quantized_tensor = torch.gather(B_expanded, 2, indices_expanded)\n",
    "    return quantized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23379c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 12\n",
    "batch_size = 7\n",
    "A = torch.randn(batch_size, num_heads, 197, 64)\n",
    "B = torch.randn(num_heads, 50, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "210e11e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(7, 12, 197, 64)\n",
    "Y = X[:, :, 0, :]\n",
    "Z = X[:, :, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "478e2df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 12, 197, 64])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = torch.cat((Y.unsqueeze(2), Z), dim=2)\n",
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "437a1471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 12, 196, 64])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29daa7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 12, 197, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = quantize(A, B)\n",
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c506a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "num_heads = 12\n",
    "batch_size = 7\n",
    "A = torch.randn(batch_size, num_heads, 197, 64)\n",
    "B = torch.randn(num_heads, 50, 64)\n",
    "\n",
    "dist_matrix = torch.cdist(A, B.unsqueeze(0), p=2) # Shape: (7, 12, 197, 50)\n",
    "selected_indices = torch.argmin(dist_matrix, dim=-1)\n",
    "B_expanded = B.unsqueeze(0).expand(batch_size, -1, -1, -1)\n",
    "indices_expanded = selected_indices.unsqueeze(-1).expand(-1, -1, -1, 64)\n",
    "R = torch.gather(B_expanded, 2, indices_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ffc3b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a679406",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.rand(2, 12, 197, 197)\n",
    "B = torch.rand(2, 12, 197, 197)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f2ee95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:3355: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.4999)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.kl_div(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0da3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 197, 64])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dist_matrix = torch.cdist(A, B, p=2) # Shape: (12, 197, 50)\n",
    "selected_indices = torch.argmin(dist_matrix, dim=2)\n",
    "indices_expanded = selected_indices.unsqueeze(-1).expand(-1, -1, 64)\n",
    "R = torch.gather(B, 1, indices_expanded)\n",
    "\n",
    "print(R.shape) # torch.Size([12, 197, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03029016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([197, 64])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(B, 0, selected_indices).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
